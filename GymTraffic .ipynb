import numpy as np
import gymnasium as gym

class GymTrafficEnv(gym.Env):
    def __init__(self):
        super(GymTrafficEnv, self).__init__()

        # Time step counter
        self.time = 0
        self.max_steps = 1800

        # Arrival probabilities
        self.arrival_prob_1 = 0.28
        self.arrival_prob_2 = 0.4

        # departure probability
        self.base_departure_prob = 0.9

        # Action space
        self.action_space = spaces.Discrete(2)

        # Observation: [q1, q2, light_status, delta]
        self.observation_space = spaces.MultiDiscrete([1811, 1811, 3, 11])

        # Queues
        self.q1 = 0
        self.q2 = 0

        # Light: 0 = Green1, 1 = Green2, 2 = R1-R2
        self.light = 0
        self.delta = 0  # Only if light == 2

        # Keeping the track of road which was green last time before turning red
        self.last_green = 0

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        self.time = 0
        self.q1 = np.random.randint(0, 11)
        self.q2 = np.random.randint(0, 11)
        self.light = np.random.choice([0, 1])  #starting with green on road 1 or 2
        self.delta = 0
        self.last_green = self.light
        return self._get_obs(), {}

    def _get_obs(self):
        return np.array([self.q1, self.q2, self.light, self.delta], dtype=np.int32)
#State Transitions
    def step(self, action):
        self.time += 1

        # Arrival
        A1 = np.random.rand() < self.arrival_prob_1
        A2 = np.random.rand() < self.arrival_prob_2

        D1 = 0
        D2 = 0

        # Departure
        if self.light == 0:  # G1
            if self.q1 > 0 and np.random.rand() < self.base_departure_prob:
                D1 = 1
        elif self.light == 1:  # G2
            if self.q2 > 0 and np.random.rand() < self.base_departure_prob:
                D2 = 1
        elif self.light == 2:  # R1-R2
            decay_prob = self._get_decay_prob(self.delta)
            if self.last_green == 0 and self.q1 > 0 and np.random.rand() < decay_prob:
                D1 = 1
            elif self.last_green == 1 and self.q2 > 0 and np.random.rand() < decay_prob:
                D2 = 1

        # updating q1 adn q2
        self.q1 = max(0, self.q1 + int(A1) - D1)
        self.q2 = max(0, self.q2 + int(A2) - D2)

        # updating light
        if self.light in [0, 1]:  # Currently green
            if action == 1:  # Switch
                self.last_green = self.light
                self.light = 2  # Enter red phase
                self.delta = 0
        elif self.light == 2:
            self.delta = min(self.delta + 1, 10)  # Cap at 10
            if self.delta >= 10:
                self.light = 1 - self.last_green
                self.delta = 0

        # Reward
        reward = - (self.q1 + self.q2)

        # Termination, Truncation 
        terminated = False
        truncated = self.time >= self.max_steps
        info = {}

        return self._get_obs(), reward, terminated, truncated, info
#decay probability
    def _get_decay_prob(self, delta):
        t = self.time - 1
        numerator = 0.9 * (10-delta) * (10+delta)
        denominator = 100
        return numerator / denominator if delta < 10 else 0
